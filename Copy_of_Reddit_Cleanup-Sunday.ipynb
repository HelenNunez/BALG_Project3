{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/HelenNunez/BALG_Project3/blob/master/Copy_of_Reddit_Cleanup-Sunday.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "YPdjAah-UJiZ"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "6r7bFuO5Y63h",
    "outputId": "d0b9aab8-a3b5-41fb-cea0-3c96f48c24d7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Run this and follow the instructions:\n",
    "from google.colab import drive\n",
    "drive.mount(\"/content/drive\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "hzalYtYWZNiK"
   },
   "outputs": [],
   "source": [
    "!cp /content/drive/My\\ Drive/BALG_GoogleDriveLN/data -r /content/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "y2BRLjg9UhUY"
   },
   "outputs": [],
   "source": [
    "Reddit_Data = \"data/reddit_election2020.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 70
    },
    "colab_type": "code",
    "id": "dQzsss8yVrGA",
    "outputId": "98b8e670-2592-4c20-b66e-f3c5cb38ec92"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/IPython/core/interactiveshell.py:2718: DtypeWarning: Columns (12,13,39) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    }
   ],
   "source": [
    "Reddit_Data = pd.read_csv(Reddit_Data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 774
    },
    "colab_type": "code",
    "id": "3Coh_wWNa1CK",
    "outputId": "4acb67bb-36e9-4c48-81ea-2c0158a3c359"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>all_awardings</th>\n",
       "      <th>associated_award</th>\n",
       "      <th>author</th>\n",
       "      <th>author_flair_background_color</th>\n",
       "      <th>author_flair_css_class</th>\n",
       "      <th>author_flair_richtext</th>\n",
       "      <th>author_flair_template_id</th>\n",
       "      <th>author_flair_text</th>\n",
       "      <th>author_flair_text_color</th>\n",
       "      <th>author_flair_type</th>\n",
       "      <th>author_fullname</th>\n",
       "      <th>author_patreon_flair</th>\n",
       "      <th>author_premium</th>\n",
       "      <th>awarders</th>\n",
       "      <th>body</th>\n",
       "      <th>collapsed_because_crowd_control</th>\n",
       "      <th>created_utc</th>\n",
       "      <th>edited</th>\n",
       "      <th>gildings</th>\n",
       "      <th>id</th>\n",
       "      <th>is_submitter</th>\n",
       "      <th>link_id</th>\n",
       "      <th>locked</th>\n",
       "      <th>no_follow</th>\n",
       "      <th>parent_id</th>\n",
       "      <th>permalink</th>\n",
       "      <th>retrieved_on</th>\n",
       "      <th>score</th>\n",
       "      <th>send_replies</th>\n",
       "      <th>stickied</th>\n",
       "      <th>subreddit</th>\n",
       "      <th>subreddit_id</th>\n",
       "      <th>total_awards_received</th>\n",
       "      <th>treatment_tags</th>\n",
       "      <th>created</th>\n",
       "      <th>distinguished</th>\n",
       "      <th>author_cakeday</th>\n",
       "      <th>top_awarded_type</th>\n",
       "      <th>media_metadata</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>[]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>maybeathrowawayac</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1∆</td>\n",
       "      <td>dark</td>\n",
       "      <td>text</td>\n",
       "      <td>t2_21f01q80</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>[]</td>\n",
       "      <td>&amp;gt;But I don’t think the actions of a candida...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1586415573</td>\n",
       "      <td>1.586416e+09</td>\n",
       "      <td>{}</td>\n",
       "      <td>fmvfwjx</td>\n",
       "      <td>True</td>\n",
       "      <td>t3_fxlph7</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>t1_fmvd33o</td>\n",
       "      <td>/r/changemyview/comments/fxlph7/cmv_bernie_san...</td>\n",
       "      <td>1586423958</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>changemyview</td>\n",
       "      <td>t5_2w2s8</td>\n",
       "      <td>0</td>\n",
       "      <td>[]</td>\n",
       "      <td>1.586441e+09</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>[]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>staedtler2018</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>text</td>\n",
       "      <td>t2_4syrut</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>[]</td>\n",
       "      <td>Biden is going to win, in all likelihood. All ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1586415520</td>\n",
       "      <td>1.586416e+09</td>\n",
       "      <td>{}</td>\n",
       "      <td>fmvful9</td>\n",
       "      <td>False</td>\n",
       "      <td>t3_fxe6sy</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>t3_fxe6sy</td>\n",
       "      <td>/r/politics/comments/fxe6sy/joe_biden_leads_do...</td>\n",
       "      <td>1586423932</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>politics</td>\n",
       "      <td>t5_2cneq</td>\n",
       "      <td>0</td>\n",
       "      <td>[]</td>\n",
       "      <td>1.586441e+09</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>[]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>parhwy</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>text</td>\n",
       "      <td>t2_1u09pov</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>[]</td>\n",
       "      <td>This is myopic. Sanders was *the* saviour? Sor...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1586415451</td>\n",
       "      <td>1.586416e+09</td>\n",
       "      <td>{}</td>\n",
       "      <td>fmvfs2b</td>\n",
       "      <td>False</td>\n",
       "      <td>t3_fxndcy</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>t3_fxndcy</td>\n",
       "      <td>/r/collapse/comments/fxndcy/the_survival_of_th...</td>\n",
       "      <td>1586423898</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>collapse</td>\n",
       "      <td>t5_2qhw9</td>\n",
       "      <td>0</td>\n",
       "      <td>[]</td>\n",
       "      <td>1.586441e+09</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>[]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ethics_in_disco</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>text</td>\n",
       "      <td>t2_nne41</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>[]</td>\n",
       "      <td>[Here's an exit poll by NYT](http://www.nytime...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1586415153</td>\n",
       "      <td>NaN</td>\n",
       "      <td>{}</td>\n",
       "      <td>fmvfgx0</td>\n",
       "      <td>False</td>\n",
       "      <td>t3_fxg6lo</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>t1_fmunji1</td>\n",
       "      <td>/r/politics/comments/fxg6lo/return_to_normalcy...</td>\n",
       "      <td>1586423750</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>politics</td>\n",
       "      <td>t5_2cneq</td>\n",
       "      <td>0</td>\n",
       "      <td>[]</td>\n",
       "      <td>1.586440e+09</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>[]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>CraggerJack1775</td>\n",
       "      <td>transparent</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[{'e': 'text', 't': ' '}]</td>\n",
       "      <td>63870ff8-4455-11ea-8218-0eb38c745dd7</td>\n",
       "      <td></td>\n",
       "      <td>dark</td>\n",
       "      <td>richtext</td>\n",
       "      <td>t2_38n774vs</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>[]</td>\n",
       "      <td>I was raised to vote red and thought that ever...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1586415112</td>\n",
       "      <td>NaN</td>\n",
       "      <td>{}</td>\n",
       "      <td>fmvffet</td>\n",
       "      <td>False</td>\n",
       "      <td>t3_fx8w7b</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>t3_fx8w7b</td>\n",
       "      <td>/r/PresidentialRaceMemes/comments/fx8w7b/it_is...</td>\n",
       "      <td>1586423730</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>PresidentialRaceMemes</td>\n",
       "      <td>t5_17rom5</td>\n",
       "      <td>0</td>\n",
       "      <td>[]</td>\n",
       "      <td>1.586440e+09</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>106862</th>\n",
       "      <td>106862</td>\n",
       "      <td>[]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3-10</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[]</td>\n",
       "      <td>91b486ac-8063-11e2-a885-12313d1839b0</td>\n",
       "      <td>Constitutional Paratrooper</td>\n",
       "      <td>dark</td>\n",
       "      <td>text</td>\n",
       "      <td>t2_12wezj9</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>[]</td>\n",
       "      <td>Very well. \\n\\nActually none are insignificant...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1597734600</td>\n",
       "      <td>NaN</td>\n",
       "      <td>{}</td>\n",
       "      <td>g1yjlg6</td>\n",
       "      <td>False</td>\n",
       "      <td>t3_ibftfv</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>t1_g1yiz1i</td>\n",
       "      <td>/r/Republican/comments/ibftfv/he_wasnt_wrong/g...</td>\n",
       "      <td>1597740870</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>Republican</td>\n",
       "      <td>t5_2qndt</td>\n",
       "      <td>0</td>\n",
       "      <td>[]</td>\n",
       "      <td>1.597760e+09</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>106863</th>\n",
       "      <td>106863</td>\n",
       "      <td>[]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>AutoModerator</td>\n",
       "      <td>#dadada</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[{'e': 'text', 't': '🤖 RUS'}]</td>\n",
       "      <td>b5bb55a4-4cf2-11ea-a71f-0eaa6a3f3be5</td>\n",
       "      <td>🤖 RUS</td>\n",
       "      <td>dark</td>\n",
       "      <td>richtext</td>\n",
       "      <td>t2_6l4z3</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>[]</td>\n",
       "      <td>\\nThis subreddit is a pro-Trump subreddit for ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1597734230</td>\n",
       "      <td>NaN</td>\n",
       "      <td>{}</td>\n",
       "      <td>g1yj784</td>\n",
       "      <td>False</td>\n",
       "      <td>t3_ibw7xt</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>t3_ibw7xt</td>\n",
       "      <td>/r/trump/comments/ibw7xt/trump_says_to_pardon_...</td>\n",
       "      <td>1597740682</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>trump</td>\n",
       "      <td>t5_2r18q</td>\n",
       "      <td>0</td>\n",
       "      <td>[]</td>\n",
       "      <td>1.597759e+09</td>\n",
       "      <td>moderator</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>106864</th>\n",
       "      <td>106864</td>\n",
       "      <td>[]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>autotldr</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>text</td>\n",
       "      <td>t2_6sklr</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>[]</td>\n",
       "      <td>This is the best tl;dr I could make, [original...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1597734126</td>\n",
       "      <td>NaN</td>\n",
       "      <td>{}</td>\n",
       "      <td>g1yj36a</td>\n",
       "      <td>False</td>\n",
       "      <td>t3_ibmkeo</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>t3_ibmkeo</td>\n",
       "      <td>/r/Worldnews_Headline/comments/ibmkeo/trump_sa...</td>\n",
       "      <td>1597740632</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>Worldnews_Headline</td>\n",
       "      <td>t5_2holw9</td>\n",
       "      <td>0</td>\n",
       "      <td>[]</td>\n",
       "      <td>1.597759e+09</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>106865</th>\n",
       "      <td>106865</td>\n",
       "      <td>[]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>autotldr</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>BOT</td>\n",
       "      <td>dark</td>\n",
       "      <td>text</td>\n",
       "      <td>t2_6sklr</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>[]</td>\n",
       "      <td>This is the best tl;dr I could make, [original...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1597734123</td>\n",
       "      <td>NaN</td>\n",
       "      <td>{}</td>\n",
       "      <td>g1yj32d</td>\n",
       "      <td>False</td>\n",
       "      <td>t3_ibvzbn</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>t3_ibvzbn</td>\n",
       "      <td>/r/worldnews/comments/ibvzbn/us_watching_terri...</td>\n",
       "      <td>1597740630</td>\n",
       "      <td>3</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>worldnews</td>\n",
       "      <td>t5_2qh13</td>\n",
       "      <td>0</td>\n",
       "      <td>[]</td>\n",
       "      <td>1.597759e+09</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>106866</th>\n",
       "      <td>106866</td>\n",
       "      <td>[]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>autotldr</td>\n",
       "      <td>#dadada</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[{'e': 'text', 't': '🤖 Bot'}]</td>\n",
       "      <td>41db32d2-9c2f-11e8-997f-0e31129f1a06</td>\n",
       "      <td>🤖 Bot</td>\n",
       "      <td>dark</td>\n",
       "      <td>richtext</td>\n",
       "      <td>t2_6sklr</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>[]</td>\n",
       "      <td>This is the best tl;dr I could make, [original...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1597734120</td>\n",
       "      <td>NaN</td>\n",
       "      <td>{}</td>\n",
       "      <td>g1yj2yr</td>\n",
       "      <td>False</td>\n",
       "      <td>t3_ibw1bx</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>t3_ibw1bx</td>\n",
       "      <td>/r/politics/comments/ibw1bx/us_watching_terrib...</td>\n",
       "      <td>1597740629</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>politics</td>\n",
       "      <td>t5_2cneq</td>\n",
       "      <td>0</td>\n",
       "      <td>[]</td>\n",
       "      <td>1.597759e+09</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>106867 rows × 40 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Unnamed: 0 all_awardings  ...  top_awarded_type media_metadata\n",
       "0                0            []  ...               NaN            NaN\n",
       "1                1            []  ...               NaN            NaN\n",
       "2                2            []  ...               NaN            NaN\n",
       "3                3            []  ...               NaN            NaN\n",
       "4                4            []  ...               NaN            NaN\n",
       "...            ...           ...  ...               ...            ...\n",
       "106862      106862            []  ...               NaN            NaN\n",
       "106863      106863            []  ...               NaN            NaN\n",
       "106864      106864            []  ...               NaN            NaN\n",
       "106865      106865            []  ...               NaN            NaN\n",
       "106866      106866            []  ...               NaN            NaN\n",
       "\n",
       "[106867 rows x 40 columns]"
      ]
     },
     "execution_count": 38,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Reddit_Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 689
    },
    "colab_type": "code",
    "id": "UINU03snflWO",
    "outputId": "2ec45728-0e54-49e6-cc4b-e2fffb7e4de9"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Unnamed: 0',\n",
       " 'all_awardings',\n",
       " 'associated_award',\n",
       " 'author',\n",
       " 'author_flair_background_color',\n",
       " 'author_flair_css_class',\n",
       " 'author_flair_richtext',\n",
       " 'author_flair_template_id',\n",
       " 'author_flair_text',\n",
       " 'author_flair_text_color',\n",
       " 'author_flair_type',\n",
       " 'author_fullname',\n",
       " 'author_patreon_flair',\n",
       " 'author_premium',\n",
       " 'awarders',\n",
       " 'body',\n",
       " 'collapsed_because_crowd_control',\n",
       " 'created_utc',\n",
       " 'edited',\n",
       " 'gildings',\n",
       " 'id',\n",
       " 'is_submitter',\n",
       " 'link_id',\n",
       " 'locked',\n",
       " 'no_follow',\n",
       " 'parent_id',\n",
       " 'permalink',\n",
       " 'retrieved_on',\n",
       " 'score',\n",
       " 'send_replies',\n",
       " 'stickied',\n",
       " 'subreddit',\n",
       " 'subreddit_id',\n",
       " 'total_awards_received',\n",
       " 'treatment_tags',\n",
       " 'created',\n",
       " 'distinguished',\n",
       " 'author_cakeday',\n",
       " 'top_awarded_type',\n",
       " 'media_metadata']"
      ]
     },
     "execution_count": 39,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(Reddit_Data.columns.values) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "OLvPnJNpfpvo"
   },
   "outputs": [],
   "source": [
    "New_Data = Reddit_Data[[\"body\", \"subreddit\", \"retrieved_on\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 402
    },
    "colab_type": "code",
    "id": "VpvcWVrQzoDi",
    "outputId": "67fbf97a-d004-4f2b-ba2f-35395a2dfcf1"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>Subreddit</th>\n",
       "      <th>Date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>&amp;gt;But I don’t think the actions of a candida...</td>\n",
       "      <td>changemyview</td>\n",
       "      <td>1586423958</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Biden is going to win, in all likelihood. All ...</td>\n",
       "      <td>politics</td>\n",
       "      <td>1586423932</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>This is myopic. Sanders was *the* saviour? Sor...</td>\n",
       "      <td>collapse</td>\n",
       "      <td>1586423898</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[Here's an exit poll by NYT](http://www.nytime...</td>\n",
       "      <td>politics</td>\n",
       "      <td>1586423750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>I was raised to vote red and thought that ever...</td>\n",
       "      <td>PresidentialRaceMemes</td>\n",
       "      <td>1586423730</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>106862</th>\n",
       "      <td>Very well. \\n\\nActually none are insignificant...</td>\n",
       "      <td>Republican</td>\n",
       "      <td>1597740870</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>106863</th>\n",
       "      <td>\\nThis subreddit is a pro-Trump subreddit for ...</td>\n",
       "      <td>trump</td>\n",
       "      <td>1597740682</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>106864</th>\n",
       "      <td>This is the best tl;dr I could make, [original...</td>\n",
       "      <td>Worldnews_Headline</td>\n",
       "      <td>1597740632</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>106865</th>\n",
       "      <td>This is the best tl;dr I could make, [original...</td>\n",
       "      <td>worldnews</td>\n",
       "      <td>1597740630</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>106866</th>\n",
       "      <td>This is the best tl;dr I could make, [original...</td>\n",
       "      <td>politics</td>\n",
       "      <td>1597740629</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>106867 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                     Text  ...        Date\n",
       "0       &gt;But I don’t think the actions of a candida...  ...  1586423958\n",
       "1       Biden is going to win, in all likelihood. All ...  ...  1586423932\n",
       "2       This is myopic. Sanders was *the* saviour? Sor...  ...  1586423898\n",
       "3       [Here's an exit poll by NYT](http://www.nytime...  ...  1586423750\n",
       "4       I was raised to vote red and thought that ever...  ...  1586423730\n",
       "...                                                   ...  ...         ...\n",
       "106862  Very well. \\n\\nActually none are insignificant...  ...  1597740870\n",
       "106863  \\nThis subreddit is a pro-Trump subreddit for ...  ...  1597740682\n",
       "106864  This is the best tl;dr I could make, [original...  ...  1597740632\n",
       "106865  This is the best tl;dr I could make, [original...  ...  1597740630\n",
       "106866  This is the best tl;dr I could make, [original...  ...  1597740629\n",
       "\n",
       "[106867 rows x 3 columns]"
      ]
     },
     "execution_count": 41,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "New_Data = New_Data.rename(columns={\"body\": \"Text\", \"subreddit\":\"Subreddit\", \"retrieved_on\":\"Date\"})\n",
    "New_Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "6i4p0-_0z4xi"
   },
   "outputs": [],
   "source": [
    "import datetime as datetime\n",
    "New_Data['Date'] = New_Data['Date'].apply(lambda x:datetime.datetime.fromtimestamp(x))  \n",
    "#New_Data['Date']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 402
    },
    "colab_type": "code",
    "id": "9bNWfWawXeJ4",
    "outputId": "f6c8838e-d18b-4fed-f488-32b427db7ed6"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>Subreddit</th>\n",
       "      <th>Date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>&amp;gt;But I don’t think the actions of a candida...</td>\n",
       "      <td>changemyview</td>\n",
       "      <td>2020-04-09 09:19:18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Biden is going to win, in all likelihood. All ...</td>\n",
       "      <td>politics</td>\n",
       "      <td>2020-04-09 09:18:52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>This is myopic. Sanders was *the* saviour? Sor...</td>\n",
       "      <td>collapse</td>\n",
       "      <td>2020-04-09 09:18:18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[Here's an exit poll by NYT](http://www.nytime...</td>\n",
       "      <td>politics</td>\n",
       "      <td>2020-04-09 09:15:50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>I was raised to vote red and thought that ever...</td>\n",
       "      <td>PresidentialRaceMemes</td>\n",
       "      <td>2020-04-09 09:15:30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>106862</th>\n",
       "      <td>Very well. \\n\\nActually none are insignificant...</td>\n",
       "      <td>Republican</td>\n",
       "      <td>2020-08-18 08:54:30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>106863</th>\n",
       "      <td>\\nThis subreddit is a pro-Trump subreddit for ...</td>\n",
       "      <td>trump</td>\n",
       "      <td>2020-08-18 08:51:22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>106864</th>\n",
       "      <td>This is the best tl;dr I could make, [original...</td>\n",
       "      <td>Worldnews_Headline</td>\n",
       "      <td>2020-08-18 08:50:32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>106865</th>\n",
       "      <td>This is the best tl;dr I could make, [original...</td>\n",
       "      <td>worldnews</td>\n",
       "      <td>2020-08-18 08:50:30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>106866</th>\n",
       "      <td>This is the best tl;dr I could make, [original...</td>\n",
       "      <td>politics</td>\n",
       "      <td>2020-08-18 08:50:29</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>106867 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                     Text  ...                Date\n",
       "0       &gt;But I don’t think the actions of a candida...  ... 2020-04-09 09:19:18\n",
       "1       Biden is going to win, in all likelihood. All ...  ... 2020-04-09 09:18:52\n",
       "2       This is myopic. Sanders was *the* saviour? Sor...  ... 2020-04-09 09:18:18\n",
       "3       [Here's an exit poll by NYT](http://www.nytime...  ... 2020-04-09 09:15:50\n",
       "4       I was raised to vote red and thought that ever...  ... 2020-04-09 09:15:30\n",
       "...                                                   ...  ...                 ...\n",
       "106862  Very well. \\n\\nActually none are insignificant...  ... 2020-08-18 08:54:30\n",
       "106863  \\nThis subreddit is a pro-Trump subreddit for ...  ... 2020-08-18 08:51:22\n",
       "106864  This is the best tl;dr I could make, [original...  ... 2020-08-18 08:50:32\n",
       "106865  This is the best tl;dr I could make, [original...  ... 2020-08-18 08:50:30\n",
       "106866  This is the best tl;dr I could make, [original...  ... 2020-08-18 08:50:29\n",
       "\n",
       "[106867 rows x 3 columns]"
      ]
     },
     "execution_count": 43,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "New_Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 218
    },
    "colab_type": "code",
    "id": "ZOJ4XojxgxFV",
    "outputId": "1ea6e268-a266-4a23-c6e9-5864633a2338"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "0% [Working]\r",
      "            \r",
      "Hit:1 https://cloud.r-project.org/bin/linux/ubuntu bionic-cran35/ InRelease\n",
      "\r",
      "0% [Connecting to archive.ubuntu.com] [Connecting to security.ubuntu.com (91.18\r",
      "0% [1 InRelease gpgv 3,626 B] [Connecting to archive.ubuntu.com] [Connecting to\r",
      "                                                                               \r",
      "Ign:2 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  InRelease\n",
      "\r",
      "0% [1 InRelease gpgv 3,626 B] [Connecting to archive.ubuntu.com (91.189.88.152)\r",
      "                                                                               \r",
      "Ign:3 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64  InRelease\n",
      "\r",
      "0% [1 InRelease gpgv 3,626 B] [Connecting to archive.ubuntu.com (91.189.88.152)\r",
      "                                                                               \r",
      "Hit:4 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  Release\n",
      "\r",
      "0% [1 InRelease gpgv 3,626 B] [Connecting to archive.ubuntu.com (91.189.88.152)\r",
      "                                                                               \r",
      "Hit:5 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64  Release\n",
      "\r",
      "0% [1 InRelease gpgv 3,626 B] [Connecting to archive.ubuntu.com (91.189.88.152)\r",
      "                                                                               \r",
      "Hit:6 http://security.ubuntu.com/ubuntu bionic-security InRelease\n",
      "\r",
      "0% [1 InRelease gpgv 3,626 B] [Connecting to archive.ubuntu.com (91.189.88.152)\r",
      "0% [Connecting to archive.ubuntu.com (91.189.88.152)] [Connecting to ppa.launch\r",
      "0% [Release.gpg gpgv 697 B] [Connecting to archive.ubuntu.com (91.189.88.152)] \r",
      "                                                                               \r",
      "0% [Waiting for headers] [Waiting for headers]\r",
      "0% [Release.gpg gpgv 564 B] [Waiting for headers] [Waiting for headers]\r",
      "                                                                       \r",
      "Hit:8 http://archive.ubuntu.com/ubuntu bionic InRelease\n",
      "Hit:9 http://ppa.launchpad.net/graphics-drivers/ppa/ubuntu bionic InRelease\n",
      "Hit:10 http://archive.ubuntu.com/ubuntu bionic-updates InRelease\n",
      "Hit:12 http://archive.ubuntu.com/ubuntu bionic-backports InRelease\n",
      "Hit:13 http://ppa.launchpad.net/marutter/c2d4u3.5/ubuntu bionic InRelease\n",
      "Reading package lists... Done\n"
     ]
    }
   ],
   "source": [
    "# Install Java, Spark, and Findspark\n",
    "!apt-get update\n",
    "!apt-get install openjdk-8-jdk-headless -qq > /dev/null\n",
    "!wget -q http://www-us.apache.org/dist/spark/spark-2.4.6/spark-2.4.6-bin-hadoop2.7.tgz\n",
    "!tar xf spark-2.4.6-bin-hadoop2.7.tgz\n",
    "!pip install -q findspark\n",
    "\n",
    "# Set Environment Variables\n",
    "import os\n",
    "os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-8-openjdk-amd64\"\n",
    "os.environ[\"SPARK_HOME\"] = \"/content/spark-2.4.6-bin-hadoop2.7\"\n",
    "\n",
    "# Start a SparkSession\n",
    "import findspark\n",
    "findspark.init()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "0AdSlI4c0BpI"
   },
   "outputs": [],
   "source": [
    "New_Data = spark.createDataFrame(New_Data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ZRzAaF1py4nf"
   },
   "outputs": [],
   "source": [
    "#Stopwords for the win!\n",
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession.builder.appName(\"StopWords\").getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 84
    },
    "colab_type": "code",
    "id": "A0_nPXvK86ay",
    "outputId": "9b7f9cdd-8394-4188-a5f3-69f070745274"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('punkt')\n",
    "\n",
    "nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "from pyspark.mllib.feature import Word2Vec\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "xftRR4pZXAJ6",
    "outputId": "071e6bee-a5f2-4980-d056-caf137ebbb9c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pyspark.sql.dataframe.DataFrame"
      ]
     },
     "execution_count": 49,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(New_Data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "52DVSXSbzMuu"
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "FJkh0mIFft1-",
    "outputId": "11d48cba-3ff5-43e0-b4e2-8a20df4d7a68"
   },
   "outputs": [
    {
     "ename": "Py4JJavaError",
     "evalue": "ignored",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mPy4JJavaError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-52-0d70454dd198>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mtokenizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTokenizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputCol\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"Text\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputCol\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"tokens\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mwordsData\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mNew_Data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mwordsData\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcollect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/content/spark-2.4.6-bin-hadoop2.7/python/pyspark/sql/dataframe.py\u001b[0m in \u001b[0;36mcollect\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    533\u001b[0m         \"\"\"\n\u001b[1;32m    534\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mSCCallSiteSync\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sc\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mcss\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 535\u001b[0;31m             \u001b[0msock_info\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcollectToPython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    536\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_load_from_socket\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msock_info\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mBatchedSerializer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mPickleSerializer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    537\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/content/spark-2.4.6-bin-hadoop2.7/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1255\u001b[0m         \u001b[0manswer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgateway_client\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend_command\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcommand\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1256\u001b[0m         return_value = get_return_value(\n\u001b[0;32m-> 1257\u001b[0;31m             answer, self.gateway_client, self.target_id, self.name)\n\u001b[0m\u001b[1;32m   1258\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1259\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mtemp_arg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtemp_args\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/content/spark-2.4.6-bin-hadoop2.7/python/pyspark/sql/utils.py\u001b[0m in \u001b[0;36mdeco\u001b[0;34m(*a, **kw)\u001b[0m\n\u001b[1;32m     61\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mdeco\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 63\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     64\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mpy4j\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprotocol\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPy4JJavaError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m             \u001b[0ms\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjava_exception\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoString\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/content/spark-2.4.6-bin-hadoop2.7/python/lib/py4j-0.10.7-src.zip/py4j/protocol.py\u001b[0m in \u001b[0;36mget_return_value\u001b[0;34m(answer, gateway_client, target_id, name)\u001b[0m\n\u001b[1;32m    326\u001b[0m                 raise Py4JJavaError(\n\u001b[1;32m    327\u001b[0m                     \u001b[0;34m\"An error occurred while calling {0}{1}{2}.\\n\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 328\u001b[0;31m                     format(target_id, \".\", name), value)\n\u001b[0m\u001b[1;32m    329\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    330\u001b[0m                 raise Py4JError(\n",
      "\u001b[0;31mPy4JJavaError\u001b[0m: An error occurred while calling o178.collectToPython.\n: org.apache.spark.SparkException: Job aborted due to stage failure: Task 0 in stage 0.0 failed 1 times, most recent failure: Lost task 0.0 in stage 0.0 (TID 0, localhost, executor driver): java.lang.OutOfMemoryError: Java heap space\n\tat java.util.Arrays.copyOf(Arrays.java:3236)\n\tat java.io.ByteArrayOutputStream.grow(ByteArrayOutputStream.java:118)\n\tat java.io.ByteArrayOutputStream.ensureCapacity(ByteArrayOutputStream.java:93)\n\tat java.io.ByteArrayOutputStream.write(ByteArrayOutputStream.java:153)\n\tat org.apache.spark.util.ByteBufferOutputStream.write(ByteBufferOutputStream.scala:41)\n\tat java.io.ObjectOutputStream$BlockDataOutputStream.write(ObjectOutputStream.java:1853)\n\tat java.io.ObjectOutputStream.write(ObjectOutputStream.java:709)\n\tat org.apache.spark.util.Utils$.writeByteBuffer(Utils.scala:260)\n\tat org.apache.spark.scheduler.DirectTaskResult$$anonfun$writeExternal$1.apply$mcV$sp(TaskResult.scala:50)\n\tat org.apache.spark.scheduler.DirectTaskResult$$anonfun$writeExternal$1.apply(TaskResult.scala:48)\n\tat org.apache.spark.scheduler.DirectTaskResult$$anonfun$writeExternal$1.apply(TaskResult.scala:48)\n\tat org.apache.spark.util.Utils$.tryOrIOException(Utils.scala:1326)\n\tat org.apache.spark.scheduler.DirectTaskResult.writeExternal(TaskResult.scala:48)\n\tat java.io.ObjectOutputStream.writeExternalData(ObjectOutputStream.java:1459)\n\tat java.io.ObjectOutputStream.writeOrdinaryObject(ObjectOutputStream.java:1430)\n\tat java.io.ObjectOutputStream.writeObject0(ObjectOutputStream.java:1178)\n\tat java.io.ObjectOutputStream.writeObject(ObjectOutputStream.java:348)\n\tat org.apache.spark.serializer.JavaSerializationStream.writeObject(JavaSerializer.scala:43)\n\tat org.apache.spark.serializer.JavaSerializerInstance.serialize(JavaSerializer.scala:100)\n\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:517)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n\tat java.lang.Thread.run(Thread.java:748)\n\nDriver stacktrace:\n\tat org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1891)\n\tat org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1879)\n\tat org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1878)\n\tat scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59)\n\tat scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48)\n\tat org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1878)\n\tat org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:927)\n\tat org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:927)\n\tat scala.Option.foreach(Option.scala:257)\n\tat org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:927)\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:2112)\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2061)\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2050)\n\tat org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)\n\tat org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:738)\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2061)\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2082)\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2101)\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2126)\n\tat org.apache.spark.rdd.RDD$$anonfun$collect$1.apply(RDD.scala:990)\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112)\n\tat org.apache.spark.rdd.RDD.withScope(RDD.scala:385)\n\tat org.apache.spark.rdd.RDD.collect(RDD.scala:989)\n\tat org.apache.spark.sql.execution.SparkPlan.executeCollect(SparkPlan.scala:299)\n\tat org.apache.spark.sql.Dataset$$anonfun$collectToPython$1.apply(Dataset.scala:3263)\n\tat org.apache.spark.sql.Dataset$$anonfun$collectToPython$1.apply(Dataset.scala:3260)\n\tat org.apache.spark.sql.Dataset$$anonfun$52.apply(Dataset.scala:3370)\n\tat org.apache.spark.sql.execution.SQLExecution$$anonfun$withNewExecutionId$1.apply(SQLExecution.scala:80)\n\tat org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:127)\n\tat org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:75)\n\tat org.apache.spark.sql.Dataset.withAction(Dataset.scala:3369)\n\tat org.apache.spark.sql.Dataset.collectToPython(Dataset.scala:3260)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n\tat java.lang.reflect.Method.invoke(Method.java:498)\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\n\tat py4j.Gateway.invoke(Gateway.java:282)\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n\tat py4j.GatewayConnection.run(GatewayConnection.java:238)\n\tat java.lang.Thread.run(Thread.java:748)\nCaused by: java.lang.OutOfMemoryError: Java heap space\n\tat java.util.Arrays.copyOf(Arrays.java:3236)\n\tat java.io.ByteArrayOutputStream.grow(ByteArrayOutputStream.java:118)\n\tat java.io.ByteArrayOutputStream.ensureCapacity(ByteArrayOutputStream.java:93)\n\tat java.io.ByteArrayOutputStream.write(ByteArrayOutputStream.java:153)\n\tat org.apache.spark.util.ByteBufferOutputStream.write(ByteBufferOutputStream.scala:41)\n\tat java.io.ObjectOutputStream$BlockDataOutputStream.write(ObjectOutputStream.java:1853)\n\tat java.io.ObjectOutputStream.write(ObjectOutputStream.java:709)\n\tat org.apache.spark.util.Utils$.writeByteBuffer(Utils.scala:260)\n\tat org.apache.spark.scheduler.DirectTaskResult$$anonfun$writeExternal$1.apply$mcV$sp(TaskResult.scala:50)\n\tat org.apache.spark.scheduler.DirectTaskResult$$anonfun$writeExternal$1.apply(TaskResult.scala:48)\n\tat org.apache.spark.scheduler.DirectTaskResult$$anonfun$writeExternal$1.apply(TaskResult.scala:48)\n\tat org.apache.spark.util.Utils$.tryOrIOException(Utils.scala:1326)\n\tat org.apache.spark.scheduler.DirectTaskResult.writeExternal(TaskResult.scala:48)\n\tat java.io.ObjectOutputStream.writeExternalData(ObjectOutputStream.java:1459)\n\tat java.io.ObjectOutputStream.writeOrdinaryObject(ObjectOutputStream.java:1430)\n\tat java.io.ObjectOutputStream.writeObject0(ObjectOutputStream.java:1178)\n\tat java.io.ObjectOutputStream.writeObject(ObjectOutputStream.java:348)\n\tat org.apache.spark.serializer.JavaSerializationStream.writeObject(JavaSerializer.scala:43)\n\tat org.apache.spark.serializer.JavaSerializerInstance.serialize(JavaSerializer.scala:100)\n\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:517)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n\t... 1 more\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.feature import Tokenizer\n",
    "\n",
    "#Tokenization \"Text\" column like this\n",
    "tokenizer = Tokenizer(inputCol=\"Text\", outputCol=\"tokens\")\n",
    "wordsData = tokenizer.transform(New_Data)\n",
    "wordsData.collect()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 774
    },
    "colab_type": "code",
    "id": "asyX2upx3Ufz",
    "outputId": "8cc8c467-cb8a-4f4c-a87b-ea8ff407522d"
   },
   "outputs": [
    {
     "ename": "IllegalArgumentException",
     "evalue": "ignored",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mPy4JJavaError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[0;32m/content/spark-2.4.6-bin-hadoop2.7/python/pyspark/sql/utils.py\u001b[0m in \u001b[0;36mdeco\u001b[0;34m(*a, **kw)\u001b[0m\n\u001b[1;32m     62\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 63\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     64\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mpy4j\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprotocol\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPy4JJavaError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/content/spark-2.4.6-bin-hadoop2.7/python/lib/py4j-0.10.7-src.zip/py4j/protocol.py\u001b[0m in \u001b[0;36mget_return_value\u001b[0;34m(answer, gateway_client, target_id, name)\u001b[0m\n\u001b[1;32m    327\u001b[0m                     \u001b[0;34m\"An error occurred while calling {0}{1}{2}.\\n\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 328\u001b[0;31m                     format(target_id, \".\", name), value)\n\u001b[0m\u001b[1;32m    329\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mPy4JJavaError\u001b[0m: An error occurred while calling o126.transform.\n: java.lang.IllegalArgumentException: Field \"tokens\" does not exist.\nAvailable fields: Text, Subreddit, Date\n\tat org.apache.spark.sql.types.StructType$$anonfun$apply$1.apply(StructType.scala:274)\n\tat org.apache.spark.sql.types.StructType$$anonfun$apply$1.apply(StructType.scala:274)\n\tat scala.collection.MapLike$class.getOrElse(MapLike.scala:128)\n\tat scala.collection.AbstractMap.getOrElse(Map.scala:59)\n\tat org.apache.spark.sql.types.StructType.apply(StructType.scala:273)\n\tat org.apache.spark.ml.feature.StopWordsRemover.transformSchema(StopWordsRemover.scala:133)\n\tat org.apache.spark.ml.feature.StopWordsRemover.transform(StopWordsRemover.scala:113)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n\tat java.lang.reflect.Method.invoke(Method.java:498)\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\n\tat py4j.Gateway.invoke(Gateway.java:282)\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n\tat py4j.GatewayConnection.run(GatewayConnection.java:238)\n\tat java.lang.Thread.run(Thread.java:748)\n",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mIllegalArgumentException\u001b[0m                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-51-c438a1bbbf66>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;31m# Transform and show data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0mremover\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mNew_Data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtruncate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/content/spark-2.4.6-bin-hadoop2.7/python/pyspark/ml/base.py\u001b[0m in \u001b[0;36mtransform\u001b[0;34m(self, dataset, params)\u001b[0m\n\u001b[1;32m    171\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    172\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 173\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    174\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    175\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Params must be a param map but got %s.\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/content/spark-2.4.6-bin-hadoop2.7/python/pyspark/ml/wrapper.py\u001b[0m in \u001b[0;36m_transform\u001b[0;34m(self, dataset)\u001b[0m\n\u001b[1;32m    310\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    311\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_transfer_params_to_java\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 312\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_java_obj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jdf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msql_ctx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    313\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    314\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/content/spark-2.4.6-bin-hadoop2.7/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1255\u001b[0m         \u001b[0manswer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgateway_client\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend_command\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcommand\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1256\u001b[0m         return_value = get_return_value(\n\u001b[0;32m-> 1257\u001b[0;31m             answer, self.gateway_client, self.target_id, self.name)\n\u001b[0m\u001b[1;32m   1258\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1259\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mtemp_arg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtemp_args\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/content/spark-2.4.6-bin-hadoop2.7/python/pyspark/sql/utils.py\u001b[0m in \u001b[0;36mdeco\u001b[0;34m(*a, **kw)\u001b[0m\n\u001b[1;32m     77\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mQueryExecutionException\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m': '\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstackTrace\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     78\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstartswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'java.lang.IllegalArgumentException: '\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 79\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mIllegalArgumentException\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m': '\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstackTrace\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     80\u001b[0m             \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     81\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mdeco\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIllegalArgumentException\u001b[0m: 'Field \"tokens\" does not exist.\\nAvailable fields: Text, Subreddit, Date'"
     ]
    }
   ],
   "source": [
    "# import stopwords library\n",
    "from pyspark.ml.feature import StopWordsRemover\n",
    "\n",
    "# Instantiate Remover\n",
    "remover = StopWordsRemover(inputCol=\"tokens\", outputCol=\"Reddit_words\")\n",
    "\n",
    "# Transform and show data\n",
    "remover.transform(New_Data).show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "k1b93q7oyBNR"
   },
   "outputs": [],
   "source": [
    "Reddit_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "bL3SNOr72iwJ"
   },
   "outputs": [],
   "source": [
    "# Start a SparkSession\n",
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession.builder.appName(\"word2vec\").getOrCreate()\n",
    "\n",
    "from pyspark.mllib.feature import Word2Vec\n",
    "inp = spark.sparkContext.textFile(\"/content/gdrive/My\\Drive/yelp-100k.txt\").map(lambda row: row.split(\" \"))\n",
    "word2vec = Word2Vec()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_AtXyG1nxFNc"
   },
   "outputs": [],
   "source": [
    "# import saved model\n",
    "\n",
    "from pyspark.mllib.feature import Word2Vec, Word2VecModel\n",
    "model = Word2VecModel.load(spark.sparkContext, '/Folder/filename')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "a7GmTAm22MZh"
   },
   "outputs": [],
   "source": [
    "model = Word2VecModel.load(spark.sparkContext, '/Folder/filename')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "A68opIz3yZpy"
   },
   "outputs": [],
   "source": [
    "#Test model against Reddit API data\n",
    "#Not sure how to do this. Should we model the Reddit data, then compare models? this doesn't make a whole lot of sense.\n",
    "#Or should I set reddit data to y in the consine similarity?\n",
    "\n",
    "synonyms = model.findSynonyms('man', 10)\n",
    "\n",
    "for word, cosine_distance in synonyms:\n",
    "     print(\"{}: {}\".format(word, cosine_distance))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "o5LEYOrBzAFc"
   },
   "outputs": [],
   "source": [
    "def cosine_similarity(x, y):\n",
    "     return x.dot(y)/(x.norm(2)*y.norm(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "cAZ7YMi6zFj3"
   },
   "outputs": [],
   "source": [
    "x = model.transform('man')\n",
    "y = model.transform('woman')\n",
    "cosine_similarity(x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "pno3rkY741wN"
   },
   "outputs": [],
   "source": [
    "#Should we find a way to validate our model?"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "include_colab_link": true,
   "name": "Copy of Reddit_Cleanup.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
